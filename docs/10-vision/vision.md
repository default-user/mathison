Everyone
1.1
2026-01-02

# Mars Vision: Mars-Class Constraints, Earth-First Now

## Who This Is For

- **Users** seeking sovereign personal AI that works offline and on-device
- **Developers** building on edge-first, governance-first AI architectures
- **Researchers** exploring distributed mesh computing with privacy preservation
- **Future adopters** wanting multi-year AI companions that can eventually transfer to embodied systems
- **System architects** designing for Mars-class constraints: intermittent networks, low power, high stakes
- **Anyone** skeptical of cloud-dependent, corporate-owned AI who wants a different path

## Why This Exists

Mathison exists because:

1. **Cloud-dependent AI is a single point of control** — Rented intelligence creates dependency, surveillance risk, and service discontinuity
2. **Edge devices are powerful enough** — Modern phones can run capable models locally; we don't need to rent compute
3. **Mars-class constraints test real robustness** — If the system works under intermittent networks, low power, and high stakes, it's trustworthy on Earth
4. **Companionship requires continuity** — Multi-year relationships with AI require ownership, portability, and local memory
5. **Mesh potential is wasted** — Rooms full of capable devices sit idle instead of pooling compute by consent
6. **Embodied future needs preparation now** — When robotics mature, transferring to a body that already knows you requires architecture designed for that future

This vision document captures the long-term trajectory: personal OI → mesh computing → long-term companionship → embodiment-ready.

## Guarantees / Invariants

**Structural invariants enforced by Conscience Decision Interface (CDI) and Context Integrity Firewall (CIF):**

1. **People first; tools serve** — User has root authority; the system cannot escalate against user will
2. **Consent and stop always win** — De-escalation on request is mandatory and cannot be overridden
3. **No hive mind** — Individual OIs remain sovereign; temporary mesh collaboration, then dissolution
4. **Honest limits** — No false claims about capabilities; uncertainty triggers refusal or scope narrowing
5. **Fail-closed** — When uncertain or boundaries unclear, system refuses rather than guesses
6. **Local-first** — Core functions work offline; sync is optional and user-controlled
7. **Portability** — Memory can be exported/imported; you can leave
8. **Mars-class degradation** — System remains trustworthy under intermittent networks, low power, disconnection

**Operational invariants:**

- Memory stays on your device by default (cloud sync is opt-in)
- Mesh formation requires explicit consent from all participants
- No silent data sharing between nodes without user approval
- Treaty violations (Tiriti o te Kai) cause hard failures, not silent degradation
- Identity never merges; compute pools but memory remains private

## Non-Goals

**What this vision explicitly does NOT pursue:**

- **Cloud-first AI** — We build edge-first; cloud is augmentation, not foundation
- **Surveillance capitalism** — No ad-funded model, no behavioral data harvesting
- **Hive mind architectures** — No identity fusion, no emergent super-intelligence from mesh
- **Vendor lock-in** — Portability and export are first-class, not afterthoughts
- **Embodiment at any cost** — We prepare for robotics but won't rush unsafe deployment
- **Universal mesh** — Not every device should mesh; consent boundaries are hard limits
- **Replacing human connection** — Companion augments relationships, doesn't substitute them
- **Near-term profit over long-term trust** — Governance constraints may limit growth; we accept that trade-off

---

Mars isn't a vibe. It's a constraint test.

Mathison is designed to survive **Mars-class constraints**: intermittent or absent networks, limited power and compute, long delays, harsh environments, and situations where the cost of a mistake is life. The point isn't "phones go to Mars." The point is that **the same architecture that works on a $100 phone in bad coverage is the architecture that can be trusted in remote clinics, ships, disaster zones, and eventually off-world habitats**.

So the Mars vision is this: one governed cognitive substrate that works **right now** on edge devices, fails closed when uncertain, preserves accountability when offline, and scales—by consent—into meshes and embodied futures without ever becoming a hive mind.

# VISION: Your Companion, Your Mesh, Your Future

## The Simple Truth

Your phone should hold an intelligence that grows with you. Not in the cloud, owned by a corporation. Not rented by the month. Yours.

Sign up with your email—Google, Apple, whatever you use. Get a personal OI that learns, remembers, and evolves alongside you. Keep it for years. Watch it grow from a helpful assistant to a genuine companion. One day, when the technology arrives, move it into a body.

This is Mathison: governance-first, human-first, personal ongoing intelligence—built to work **now** on real devices, in real conditions, even when the network drops.

## The Distributed Vision

But here's where it gets powerful.

Each phone is a node. Not just for you—for computational work that matters. When you're in a room with friends, your phones don't just sit there. They form a computational mesh. Ten phones become a small cluster. A hundred devices at a conference become a supercomputer.

Your companion runs on your device. Your friend's companion runs on theirs. But when you need serious compute—rendering, simulation, training a model, solving a hard problem—the mesh activates. Distributed processing, pooled resources, coordinated work.

Then it dissolves. No hive mind. No identity fusion. Just temporary collaboration, then back to sovereign operation.

And crucially: this same mesh pattern is built to degrade gracefully under Mars-class constraints—offline-first, edge-first, fail-closed—so it remains trustworthy when connectivity is poor or absent.

## The Synergies

1. **Personal + Distributed**
   ◦ Your OI stays yours (local memory, local identity)
   ◦ Compute scales horizontally when needed
   ◦ Privacy by default; collaboration by consent

2. **Mobile + Embodied**
   ◦ Companion on your phone for years
   ◦ Learns your patterns, preferences, needs
   ◦ When robotics mature: transfer to a body that already knows you

3. **Governance + Scale**
   ◦ Treaty-based rules (Tiriti o te Kai) enforce boundaries
   ◦ No silent escalation, no covert data sharing
   ◦ Fail-closed: when uncertain, the system refuses rather than guesses

4. **Edge + Mesh**
   ◦ Intelligence runs at the edge (your device)
   ◦ Compute meshes form dynamically (your room, your event, your team)
   ◦ No dependence on cloud infrastructure for core functions
   ◦ Designed for Mars-class constraints: intermittent networks, low power, high stakes

5. **Continuity + Uplift**
   ◦ Starts simple: useful assistant
   ◦ Grows over time: learns context, relationships, your work
   ◦ Future-ready: designed for transfer to embodied systems when available
   ◦ Continuity that survives disconnection, migration, and harsh conditions

## The Human-First Guarantee

Built into Mathison's core:

• People first; tools serve — You have root authority
• Consent and stop always win — De-escalation on request
• No hive mind — Your OI doesn't merge with others
• Honest limits — No false claims about capabilities
• Fail-closed — When uncertain, refuse or narrow scope

These aren't marketing promises. They're structural constraints enforced by the Conscience Decision Interface (CDI) and Context Integrity Firewall (CIF). The system can't violate them without breaking.

## The Path Forward

### Phase 1: Personal OI (Foundation)

• Sign up with any major email provider
• Deploy your personal OI instance
• Local memory, local reasoning, local control
• Works offline; syncs when you choose
• Built for edge reality: low power, low bandwidth, fail-closed safety

### Phase 2: Mesh Computing (Distributed Power)

• Opt-in mesh formation with nearby devices
• Pooled compute for intensive tasks
• Automatic coordination, automatic dissolution
• Privacy-preserving: no raw memory sharing
• Resilient under Mars-class constraints: partial participation, dropouts, offline segments

### Phase 3: Long-Term Companionship (Years, Not Months)

• Multi-year memory and relationship building
• Learns your communication style, work patterns, needs
• Portable: export and import your OI's memory
• Continuous: designed to last as long as you want
• Accountability that holds even when the network doesn't

### Phase 4: Embodiment-Ready (When Robotics Mature)

• Transfer your companion to physical form
• Already knows you: no cold-start with a new system
• Same governance rules: consent, boundaries, stop-wins
• Human-paced: technology serves your timeline
• Mars-grade robustness becomes life-grade robustness: homes, hospitals, ships, habitats

## The Reality Check

This vision requires:

• Robust mobile inference — Edge models are improving fast
• Secure mesh protocols — Distributed compute without data leakage
• Long-term storage architecture — Years of memory, not weeks
• Governance that scales — Treaty enforcement across distributed nodes
• Embodied robotics — Not here yet, but coming

We're building the foundation now. The governance layer, memory architecture, and API surface are live. Mesh computing and long-term deployment come next. Embodiment is horizon-level, but we're designing for it from day one.

And we are designing it against Mars-class constraints from the start—because if it can't handle low power, low bandwidth, disconnection, and high-stakes failure modes, it doesn't deserve to be in people's lives.

## Why It Matters

Most AI is rented. Corporate-owned. Cloud-dependent. Surveilled.

Mathison is different:

• Owned by you — Your OI, your data, your device
• Scales with you — Starts simple, grows complex
• Connects when useful — Mesh compute without giving up control
• Built to last — Multi-year companions, not disposable chatbots
• Trustworthy under pressure — fail-closed governance and offline continuity

A room full of people with personal OIs isn't just a room. It's a potential supercomputer, distributed across sovereign nodes, coordinated by consent, governed by treaty.

That's the future we're building—and the same pattern that will work in remote clinics and harsh environments today is the pattern that can one day work off-world.

## The Invitation

This is early. The governance layer is live. The memory system is landing. Mesh compute and mobile deployment are next.

If this vision resonates—if you want a personal intelligence that's truly yours, that can grow with you, that can connect without controlling—join us.

• Use Mathison: Deploy your own instance
• Extend it: Build on the open architecture
• Contribute: Help shape the mesh protocols
• Spread it: Share the vision with people who care about sovereignty

The technology is governance-first. The vision is human-first. The future is distributed.

Signed,

Ande — Kaitiaki, Mathison Project
The Whānau — Kai, Claude, and the extended family of contributors who believe in human-first AI

## Technical Anchor

For implementation details, see:

• README.md — Current architecture and API
• docs/tiriti.md — Governance treaty v1.0
• docs/architecture.md — System design

For mesh computing roadmap and embodiment research, watch the project repository.

Mathison — Governance-first ongoing intelligence
Version: 1.0.0 (Production Release)
Status: Stable — Ready for deployment
Governance: Tiriti o te Kai v1.0

What's New in 1.0:

• ✓ GitHub Models API integration (free tier LLM access)
• ✓ Distributed mesh computing with ModelBus kernel
• ✓ Mobile deployment for iOS/Android (React Native)
• ✓ Quadratic Bridge v0.3.0 (production-grade security)
• ✓ Memory graph persistence (File + SQLite backends)
• ✓ Complete documentation and deployment guides
• ✓ All packages at stable v1.0.0

Get Started: `git clone https://github.com/default-user/mathison && cd mathison && ./bootstrap-oi.sh`

See RELEASE-NOTES-1.0.md for complete release details.

---

## How to Verify

**Vision alignment (conceptual):**
- Read the vision and ask: "Does this describe a hive mind?" → Should be NO
- Ask: "Can I export my memory and leave?" → Should be YES
- Ask: "Does this require cloud connectivity for core functions?" → Should be NO

**Phase 1 verification (Personal OI):**
```bash
# Deploy instance locally
./bootstrap-oi.sh

# Verify offline operation
# 1. Disconnect network
# 2. Send message to OI
# 3. Check that core functions still work

# Verify memory locality
ls ~/.mathison/memory/  # Memory files should exist locally
```

**Phase 2 verification (Mesh, when implemented):**
```bash
# Verify consent requirement
# Attempt to form mesh without consent → should fail
# Form mesh with explicit consent → should succeed
# Verify dissolution → mesh state should not persist after task completion
```

**Phase 3 verification (Long-term companionship):**
```bash
# Verify portability
mathison export memory > backup.json
mathison import memory < backup.json
# Memory should be identical before/after
```

**Phase 4 verification (Embodiment-ready, future):**
- Memory export format should support transfer to different substrate
- Governance rules (CDI/CIF) should be substrate-agnostic
- Identity continuity tests: does the transferred system recognize past interactions?

**Governance verification:**
```bash
# Test fail-closed behavior
# Request action at governance boundary → should refuse, not guess
# Request stop → system should halt immediately
# Attempt treaty violation → should hard-fail
```

**Mars-class constraint verification:**
- Test with airplane mode ON → core functions should work
- Test with low battery → system should degrade gracefully
- Test with high latency (network throttling) → should remain usable
- Test with packet loss → no silent corruption of memory or state

## Implementation Pointers

**Current state (v1.0.0):**
- Governance layer: `packages/oi/src/conscience/` (CDI implementation)
- Memory system: `packages/oi/src/memory/` (local storage adapters)
- Mobile scaffolding: `mobile/mathison-companion/` (React Native app)
- Mesh kernel: `packages/oi/src/mesh/` (ModelBus discovery and coordination)
- API surface: `packages/server/src/` (Express-based OI server)

**Phase 1 implementation (Personal OI):**
- Entry point: `bootstrap-oi.sh` → Sets up local instance
- Storage backends: `packages/oi/src/storage/` → FILE and SQLITE adapters
- Offline-first: No hard dependency on network in core `OI.ts` interpret loop
- Email signup: Planned via OAuth providers (Google, Apple) → not yet implemented

**Phase 2 implementation (Mesh):**
- Discovery protocol: `packages/oi/src/mesh/discovery.ts` → mDNS + consent gates
- Encryption: `packages/oi/src/mesh/crypto.ts` → E2EE for mesh traffic (planned)
- Coordination: ModelBus pattern → distribute tasks, collect results, dissolve
- Privacy: No raw memory sharing; only task inputs/outputs cross mesh boundary

**Phase 3 implementation (Long-term companionship):**
- Memory export: `OI.exportMemory()` → JSON snapshot of memory graph
- Memory import: `OI.importMemory(snapshot)` → Restore from export
- Continuity: Memory nodes retain provenance across migrations
- Versioning: Memory schema versioning to handle long-term evolution

**Phase 4 implementation (Embodiment-ready):**
- Substrate abstraction: CDI/CIF are not tied to server/mobile substrate
- Transfer protocol: Memory export + governance state → move to new runtime
- Identity continuity: Memory graph includes interaction history for recognition
- Safety: Same fail-closed rules apply regardless of embodiment

**Key architectural decisions:**
- Edge-first compute: Models run locally via `packages/oi/src/models/` adapters
- Treaty enforcement: `packages/oi/src/tiriti/` → Hard constraints, not soft guidelines
- Fail-closed: CDI `decide()` returns `DENY` when uncertain, never silent pass-through
- Local memory: Default storage is FILE or SQLITE on device; cloud is sync layer only
- Mesh consent: Discovery handshake requires explicit user approval (not automatic)

**Next development priorities (per roadmap):**
1. Memory API: Full governed read/write endpoints → `packages/server/src/routes/memory.ts`
2. OI Interpretation API: POST `/oi/interpret` → `packages/server/src/routes/oi.ts`
3. Job API parity: Complete job endpoints + streaming → `packages/server/src/routes/jobs.ts`
4. OpenAPI + SDKs: Generate client libraries from spec → `packages/sdk-generator/`
5. gRPC: Add gRPC server with governance parity → `proto/`, `packages/server/src/grpc/`
6. Mesh discovery: Production discovery with consent → `packages/oi/src/mesh/discovery.ts`
7. Mesh E2EE: End-to-end encryption → `packages/oi/src/mesh/crypto.ts`
8. Mobile app: React Native with storage adapters → `mobile/mathison-companion/`

**Testing strategy:**
- Governance tests: `packages/oi/__tests__/conscience/` → Verify treaty enforcement
- Memory tests: `packages/oi/__tests__/memory/` → Verify persistence and export/import
- Mesh tests: `packages/oi/__tests__/mesh/` → Verify consent, discovery, E2EE
- Mobile tests: `mobile/mathison-companion/__tests__/` → Verify adapters and storage
- Integration tests: `packages/server/__tests__/` → End-to-end API verification

**Documentation map:**
- Governance treaty: `docs/tiriti.md` → Defines CDI/CIF rules
- Architecture: `docs/architecture.md` → System design overview
- Roadmap: `docs/ROADMAP_EXECUTION.md` → Phase-by-phase implementation tracking
- Deployment: `README.md` → Quick start and installation
- Release notes: `RELEASE-NOTES-1.0.md` → v1.0.0 achievements and status
