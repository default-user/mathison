# v2.2 Model Bus Specification

## Overview

The Model Bus is the v2.2 architecture for governed access to external AI model APIs. It ensures that **all model calls flow through governed handlers with capability tokens**, preventing direct vendor API access anywhere else in the codebase.

## Architecture

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                           HTTP Request                                       │
│                    POST /threads/:thread_id/ai/chat                          │
└──────────────────────────────────────┬──────────────────────────────────────┘
                                       │
                                       ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                         Unified Governed Pipeline                           │
│  ┌─────────┐  ┌─────────────┐  ┌─────────┐  ┌────────────┐  ┌──────────┐  │
│  │ CIF     │→│ CDI Action  │→│ ai.chat │→│ CDI Output │→│ CIF      │  │
│  │ Ingress │  │ Check       │  │ Handler │  │ Check      │  │ Egress   │  │
│  └─────────┘  └─────────────┘  └─────────┘  └────────────┘  └──────────┘  │
│                     │                │                                      │
│                     │ mints          │ uses                                 │
│                     ▼                ▼                                      │
│              ┌─────────────┐  ┌──────────────┐                             │
│              │ Capability  │  │ Model Router │                             │
│              │ Tokens      │  │ (capability  │                             │
│              └─────────────┘  │  enforced)   │                             │
└───────────────────────────────┴──────┬───────┴─────────────────────────────┘
                                       │
                                       ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                            @mathison/model-bus                              │
│  ┌───────────────┐  ┌───────────────┐  ┌───────────────┐                   │
│  │ OpenAI        │  │ Anthropic     │  │ Local/Mock    │                   │
│  │ Adapter       │  │ Adapter       │  │ Adapter       │                   │
│  └───────┬───────┘  └───────┬───────┘  └───────┬───────┘                   │
│          │                  │                  │                            │
│          └──────────────────┼──────────────────┘                            │
│                             │                                               │
│                    ┌────────▼────────┐                                      │
│                    │  HTTP Client    │ ← Single point for all vendor calls  │
│                    │  (internal)     │                                      │
│                    └─────────────────┘                                      │
└─────────────────────────────────────────────────────────────────────────────┘
                                       │
                                       ▼
                              Vendor APIs (OpenAI, Anthropic)
```

## Key Components

### ModelRouter

The `ModelRouter` is the central component that:

1. **Verifies capability tokens** before any adapter call
2. **Routes requests** to the appropriate adapter based on `model_id`
3. **Enforces namespace boundaries** (token's `oi_id` must match request's `namespace_id`)

```typescript
import { createModelRouter, createGateway } from '@mathison/model-bus';

const gateway = createGateway({
  allowed_model_families: ['openai', 'anthropic', 'local'],
});

const router = createModelRouter(gateway, {
  providers: {
    openai: { api_key: process.env.OPENAI_API_KEY },
    anthropic: { api_key: process.env.ANTHROPIC_API_KEY },
    local: {},
  },
});
```

### Adapters

Each adapter implements the `ModelBusAdapter` interface:

| Adapter | Provider | Supported Models | Environment Variable |
|---------|----------|------------------|---------------------|
| OpenAI | `openai` | `gpt-4*`, `gpt-3.5*`, `o1*`, `o3*` | `OPENAI_API_KEY` |
| Anthropic | `anthropic` | `claude-3*`, `claude-2*`, `claude-opus*`, `claude-sonnet*` | `ANTHROPIC_API_KEY` |
| Local | `local` | `local*`, `mock*`, `test*` | None |

### HTTP Client

All vendor API calls go through a single internal HTTP client (`http-client.ts`):

- Centralized error handling and retries
- Consistent timeouts
- Audit-friendly (single place to log all external calls)

## Capability Token Requirements

The `ai.chat` intent requires three capabilities:

| Capability | Purpose |
|-----------|---------|
| `model_invocation` | Authorize the model API call |
| `memory_read` | Read thread messages for context |
| `memory_write` | Write user/assistant messages and provenance events |

The CDI layer mints these tokens during the action check phase. The handler retrieves the `model_invocation` token and passes it to the router.

## Provenance Logging

Every model invocation logs a provenance event containing:

```typescript
{
  event_type: 'model_invocation',
  payload: {
    provider: 'openai' | 'anthropic' | 'local',
    model_id: 'gpt-4-turbo' | 'claude-3-opus' | etc,
    usage: {
      input_tokens: number,
      output_tokens: number,
      total_tokens: number
    },
    latency_ms: number,
    trace_id: string,         // Correlation ID
    capability_token_id: string, // Token that authorized this call
    vendor_request_id: string,   // Vendor's request ID (if available)
    finish_reason: 'stop' | 'length' | 'error' | 'content_filter'
  }
}
```

## No-Bypass Enforcement

See [v2.2-no-bypass-enforcement.md](./v2.2-no-bypass-enforcement.md) for details on the CI tests that prevent vendor calls outside the Model Bus.

## Usage Example

```typescript
// HTTP Request
POST /api/v2.2/threads/550e8400-e29b-41d4-a716-446655440000/ai/chat
X-Principal-Id: user-123

{
  "namespace_id": "my-namespace",
  "model_id": "gpt-4-turbo",
  "user_input": "What is the capital of France?",
  "parameters": {
    "temperature": 0.7,
    "max_tokens": 1000,
    "system_prompt": "You are a helpful assistant."
  }
}

// Response
{
  "success": true,
  "data": {
    "content": "The capital of France is Paris.",
    "usage": {
      "input_tokens": 25,
      "output_tokens": 10,
      "total_tokens": 35
    },
    "model_id": "gpt-4-turbo",
    "provider": "openai",
    "trace_id": "550e8400-e29b-41d4-a716-446655440001"
  },
  "trace_id": "550e8400-e29b-41d4-a716-446655440001"
}
```

## Configuration

### Environment Variables

```bash
# Model API Keys
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...

# Optional: Custom base URLs (for proxies or self-hosted)
# OPENAI_BASE_URL=https://your-proxy.com
# ANTHROPIC_BASE_URL=https://your-proxy.com
```

### Routing Configuration

```typescript
const router = createModelRouter(gateway, {
  default_provider: 'openai', // Fallback if no pattern matches
  providers: {
    openai: {
      api_key: process.env.OPENAI_API_KEY,
      timeout_ms: 60000,
    },
    anthropic: {
      api_key: process.env.ANTHROPIC_API_KEY,
      timeout_ms: 120000,
    },
    local: {},
  },
  model_overrides: {
    'special-model': 'anthropic', // Force specific model to specific provider
  },
});
```
